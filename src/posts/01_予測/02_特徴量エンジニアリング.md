---
title: '特徴量エンジニアリング'
created: '2023/01/01'
update: '2023/03/01'
tags: 
    - 競馬予想
    - Python
---

前回の記事では、netkeibaから取得したレース情報をスクレイピングし、Pandasを使ってデータ整形を行いました。今回は、整形されたデータをもとに競馬予想システムの構築に進みます。

競馬予想には、豊富な特徴量が必要です。レースの距離やコース状況、過去の成績など、さまざまな要素が組み合わさって予想の精度が向上します。ここでは、特徴量エンジニアリングとモデル構築について解説します。

まずは、特徴量エンジニアリングから始めましょう。以下のコードでは、先ほど整形したデータをもとに特徴量を生成しています。

```python
# 特徴量エンジニアリング
df["race_distance"] = df["race_name"].apply(lambda x: int(x.split("m")[0]))
df["race_course"] = df["race_name"].apply(lambda x: x.split(" ")[-1])

# データの表示
print(df)
```

上記のコードでは、`race_name`からレースの距離を抽出して`race_distance`列を作成し、レースのコースを抽出して`race_course`列を作成しています。これにより、距離やコースといった重要な情報が特徴量として追加されました。

次に、LightGBMを使ってモデルの構築を行います。LightGBMは勾配ブースティング法に基づく機械学習モデルであり、競馬予想において高い精度を示すことが知られています。

```python
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# 特徴量と目的変数の設定
X = df[["race_distance", "race_course"]]
y = df["target_variable"]

# 訓練データとテストデータに分割
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# LightGBMモデルの構築と学習
model = lgb.LGBMClassifier()
model.fit(X_train, y_train)

# テストデータでの予測
y_pred = model.predict(X_test)

# 精度の評価
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)
```

上記のコードでは、`race_distance`と`race_course`を特徴量として抽出し、目的変数である`target_variable`としていることを前提にモデルを構築しています。`train_test_split`関数を使用してデータを訓練データとテストデータに分割し、`LGBMClassifier`を用いてLightGBMモデルを構築しています。

そして、訓練データを用いてモデルを学習させ、テストデータでの予測を行いました。最後に、予測結果の精度を評価するために`accuracy_score`関数を使用し、正解率（Accuracy）を表示しています。

このように、特徴量エンジニアリングとモデル構築を組み合わせることで、競馬予想システムを構築する基本的な手順が完了しました。次回の記事では、モデルの評価やパラメータチューニングについて詳しく解説します。

