{"componentChunkName":"component---src-templates-tags-js","path":"/note/AI/","result":{"data":{"postsRemark":{"edges":[{"node":{"id":"a661b407-d4c6-5c86-8417-c337b2931b42","rawMarkdownBody":"\n### 1. プロンプトの詳細な記述\n\nプロンプトは画像の内容を最大限詳細に記述します。\n\n```\n白黒の子猫がソファの上で丸くなって眠っている。光が差し込んでいる。リアルでクオリティの高い画像。\n```\n\n- 子猫の毛色、起きている状態、光の加減など細かい要素を指定する。\n- 画質に関する指示も含める。\n\n### 2. テンプレートプロンプト\n\n```\n{人物}が{行為}をしているリアルな画像\n```\n\n- 中括弧{}で変数を設定し、繰り返し使えるテンプレートを作成。\n\n### 3. ネガティブプロンプト\n\n```\n{内容}, low qualityではない, cartoonではない\n``` \n\n- 画像に含めたくない要素を否定形式で指定する。\n\n### 4. 設定ファイル\n\nconfig.yaml:\n\n```yaml\nimage_size: 512\nbatchSize: 1 \n...\n```\n\n- 画像サイズ、バッチサイズなどのパラメータを設定。\n\n### 5. GPUの指定\n\nlaunch.py:\n\n```python\n--gpu 0\n```\n\nconfig.yaml:\n\n```yaml \ndevice: cuda:0\n```\n\n- 第一GPUを使うよう指定。\n\n### 6. 画像の保存\n\n```python\nfrom diffusers import ImagePipeline\n\nimage = model.decode(prompt) \n\nImagePipeline.save_image(image, \"cat.png\")\n```\n\n- ImagePipelineを使って画像を保存。\n\n### 7. ハイパラメータ調整\n\n```\nguidance_scale: 7.5 \nnum_inference_steps: 50\n``` \n\n- 学習率、イテレーション回数などを調整。\n\nこのように実際のコード例も合わせることで、Stable Diffusionの利用がよりイメージしやすくなると思います。","frontmatter":{"title":"画像生成を始めるための手順","tags":["AI","Python","StableDiffusion"],"update":"2023/09/03"}}},{"node":{"id":"8e626e82-1705-58b2-a5c9-80119846cd6d","rawMarkdownBody":"\n\nStable Diffusionは、テキストのプロンプトから高品質な画像を生成できる最新のAIです。本記事では、Stable Diffusionをローカルマシンに構築する方法を紹介します。\n\n## メリット\n\nStable Diffusionをローカルで構築するメリットは以下の通りです。\n\n- プライバシー保護 - クラウドサービスを使わずローカルで完結するため、個人情報が外部に漏れるリスクが低減します。\n\n- コスト削減 - クラウドサービスの利用料金がかからないためコストを大幅に抑えられます。\n\n- カスタマイズが容易 - ローカルなら設定を自由に変更でき、学習データやハイパラメータの調整が簡単です。\n\n## 必要な環境\n\nローカルでStable Diffusionを動かすには、以下のようなマシンスペックが必要です。\n\n- GPU: NVIDIA RTXシリーズ等の高性能GPU\n- CPU: Intel Core i7等の高速マルチコアCPU\n- RAM: 16GB以上 \n- ストレージ: 10GB以上の空き容量\n\nソフトウェア環境としては以下が必要です。\n\n- Python 3.7以上\n- PyTorch 1.7以上  \n- CUDA Toolkit\n- cuDNN\n- Docker\n\n## インストール手順\n\n### 1. 必要なソフトウェアのインストール\n\n- Pythonの最新安定版をインストール\n- PyTorchをpipでインストール\n- NVIDIAサイトからCUDA ToolkitとcuDNNをダウンロード\n- Dockerをインストール\n\n### 2. 学習済みモデルのダウンロード\n\n- diffusersライブラリを使ってモデルをダウンロード\n\n```\ngit clone https://github.com/huggingface/diffusers.git\ncd diffusers\npip install -e .\n```\n\n### 3. Stable Diffusionリポジトリのクローン\n\n- git clone コマンドでリポジトリをクローン\n\n```\ngit clone https://github.com/CompVis/stable-diffusion.git\n```\n\n### 4. config.yamlの設定変更\n\n- 画像サイズ等の設定を必要に応じて変更\n\n### 5. ローンチャースクリプトで起動\n\nこのように、順を追ってインストールしていけばローカルでの構築はできますが、設定次第でエラーが発生することもあります。トラブルシューティングのためにも、各手順の理解とバージョン確認が大切です。\n\nStable Diffusionを使えるようになれば、プライベートな環境で好きなようにテキストから画像生成を楽しむことができます。ローカル構築には多少の手間は掛かりますが、カスタマイズの自由度が高くなるのでオススメです。\n\n以上、Stable Diffusionのローカル構築方法でした。実際に設定していく過程で分からないことがあれば、公式ドキュメントやフォーラムを参考にしてください。\n","frontmatter":{"title":"StableDiffusionをローカルに構築する","tags":["AI","Python","StableDiffusion"],"update":"2023/08/13"}}}]}},"pageContext":{"tag":"AI"}},"staticQueryHashes":["1251307220","772138545"],"slicesMap":{}}